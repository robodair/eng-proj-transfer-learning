{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Image Classification with Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What to take away from this presentation\n",
    "\n",
    "- Python is a good choice for machine learning\n",
    "- Jupyter Notebooks for easy experimentation\n",
    "- Basic understanding of a Convolutional Neural Network (CNN)\n",
    "- What transfer learning is\n",
    "- Basic understanding of the requirements for training a CNN\n",
    "- Familiarity with using the Keras framework and some other tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Tools\n",
    "\n",
    "- Jupyter Notebooks: Browser-based python console that makes using Python easy\n",
    "- Keras: A popular machine leaning framework and library for Python\n",
    "- Tensorflow: A backend for Keras, as well as machine learning framework on its own.\n",
    " - Tensorflow is a library for high performance numerical computation.\n",
    "- Tensorboard: Web Dashboard for visualizing tensorflow model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WH2h1peGw_-D"
   },
   "source": [
    "## What is a CNN?\n",
    "\n",
    "You can generally think of a CNN being used for image classification as having two major sections, responsible for feature extraction and classification.\n",
    "\n",
    "The layers in a neural network that perform classification are usually referred to as the 'fully connected' layers, in our transfer learning example it is the weights or these layers that we'll be updating.\n",
    "\n",
    "Initial layers in the CNN are for extracting features from the images to make the job of the fully connected layers easier (e.g. filtering, convolutions, pooling)\n",
    "\n",
    "An in-depth explanation of neural net architectures is beyond the scope of this talk, though if you have any burning questions I can try and help you out. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CNN](https://cdn-images-1.medium.com/max/1200/1*XbuW8WuRrAY5pC4t-9DZAQ.jpeg)\n",
    "https://medium.com/@RaghavPrabhu/understanding-of-convolutional-neural-network-cnn-deep-learning-99760835f148"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training a network what you are actually doing is minimising the loss function, this has to do with derivatives and simultaneous equations where you continuously make small changes to the network weights to improve the classification accuracy as you train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Transfer Learning?\n",
    "\n",
    "Taking advantage of existing work done in the image classification field.\n",
    "\n",
    "Specifically, building on the feature extraction layers of existing CNN architectures.\n",
    "\n",
    "To do just that we can take a network that someone else has spent a long time training and just borrow the feature extraction bits of it, already pre-trained, typically these consist of convolution and pooling layers. We attach those borrowed layers onto some additional fully connected layers (the neural network) and train the complete model on our specific dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting into some code\n",
    "We're just going to make all our Python imports up front to make code in later cells cleaner, imports are how you include external code in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NgRNbYGvw_-E"
   },
   "outputs": [],
   "source": [
    "# Keras Framework\n",
    "import keras as K\n",
    "# Numpy - matrix math library for Python written in C\n",
    "import numpy as np\n",
    "# Tensorflow Framework\n",
    "import tensorflow as tf\n",
    "# Matlab-like plotting library and\n",
    "# enable interactive jupyter notebook plote of appropriate size\n",
    "%matplotlib notebook\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = 9.5, 6\n",
    "import matplotlib.pyplot as plt\n",
    "# scikit-learn, another machine learning framework that provides a lot of useful utilities\n",
    "import sklearn\n",
    "# General python standard library tools\n",
    "import itertools\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6dIDPsfIw_-I"
   },
   "source": [
    "## Obtain Dataset - CIFAR10\n",
    "\n",
    "We'll be using the CIFAR10 dataset for the example, CIFAR10 is a dataset containing 50,000 32 by 32 RGB training images and 10,000 test images split into 10 categories.\n",
    "\n",
    "Here's an example of some of those:\n",
    "\n",
    "![cifar10](http://corochann.com/wp-content/uploads/2017/04/cifar10_plot_more.png)\n",
    "\n",
    "Keras includes a copy of this dataset that's easily accessible entirely from code, so we can just import the data and begin using it (after waiting for it to download the first time we import it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PF9irx9pw_-I"
   },
   "outputs": [],
   "source": [
    "(input_train_orig, truth_train_orig), (input_test_orig, truth_test_orig) = K.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFAR10 provides image truth as single number in the range 0-9, but we need a categorical representation, Keras provides us a function to generate this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SB7I7lUaw_-O"
   },
   "outputs": [],
   "source": [
    "TRUTH_CLASSES = 10\n",
    "truth_train = K.utils.to_categorical(truth_train_orig, TRUTH_CLASSES)\n",
    "truth_test = K.utils.to_categorical(truth_test_orig, TRUTH_CLASSES)\n",
    "print(\"Original Truth Format Example:   \", truth_train_orig[0])\n",
    "print(\"Categorical Truth Format Example:\", truth_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having loaded the dataset, we can plot a preview of some of the images to check what they look like, and what they're classified as."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tth60ihp0rrh",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_images(images, truths, rng, preds=None):\n",
    "    \"\"\"Plot some images labelled with their truth, and optionally the prediction the network made\"\"\"\n",
    "    \n",
    "    labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    cols = 5\n",
    "    rows = len(rng) // cols\n",
    "    plt.figure()\n",
    "    \n",
    "    truths = np.argmax(truths, axis=1)\n",
    "    if preds is not None:\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "\n",
    "    for i, idx in enumerate(rng):\n",
    "        truth = labels[truths[idx]]\n",
    "        plt.subplot(rows, cols, i+1)\n",
    "        title = '{truth}'.format(truth=truth)\n",
    "        color = 'b'\n",
    "        if preds is not None:\n",
    "            color = 'g'\n",
    "            pred = labels[preds[idx]]\n",
    "            join = '=='\n",
    "            if pred != truth:\n",
    "                color = 'r'\n",
    "                join = '!='\n",
    "            title = '\"{pred}\" {join} '.format(pred=pred, join=join) + title\n",
    "            \n",
    "        plt.title(title, color=color)\n",
    "        plt.imshow(images[idx])\n",
    "    plt.tight_layout()\n",
    "        \n",
    "plot_images(input_train_orig, truth_train, range(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kWqMmDNkw_-R"
   },
   "source": [
    "# Import a pre-trained Model (VGG19)\n",
    "\n",
    "To kick start our classification we'll base our model off the VGG19 CNN model, like getting a copy of CIFAR 10, Keras provides us an easy way to download this pre-trained model.\n",
    "\n",
    "VGG has been pre-trained on another well-known dataset, ImageNet, so the convolutional layers will already be pretty good at extracting features from the images. \n",
    "\n",
    "Note the `include_top` argument when importing the model is false - this is a convenience feature for transfer learning when importing models in Keras, it means that the importd model doe not include fully-connected layers, so that we can define our own and attach them easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sl2-pt6rw_-S"
   },
   "outputs": [],
   "source": [
    "# The minimum image size that our pre-trained imported VGG19 supports is 48x48\n",
    "# We will have to upscale our training images before we can train the network\n",
    "INPUT_DIM = 48;\n",
    "\n",
    "vgg19 = K.applications.vgg19.VGG19(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(INPUT_DIM, INPUT_DIM, 3),\n",
    ")\n",
    "\n",
    "# The imported layers are already trained in ImageNet,\n",
    "# So we can mark them as not trainable to prevent weights modification\n",
    "for layer in vgg19.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MAQSN9L6w_-U"
   },
   "source": [
    "Keras provides a method for us to summarise a model as text, we can inspect what we've downloaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ct9iMz0aw_-U"
   },
   "outputs": [],
   "source": [
    "vgg19.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WZGeT-xIw_-Z"
   },
   "source": [
    "# Image Preprocessing\n",
    "\n",
    "If we scroll up and look at the input layer of our model - note the expected input size of 48x48x3 (the 3 is for the RGB channels), but remember the CIFAR10 images are 32x32:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zBABhJqlw_-Z"
   },
   "outputs": [],
   "source": [
    "print('Train Input Shape, 50000 items):', input_train_orig.shape)\n",
    "print('Test Input Shape, 10000 items): ', input_test_orig.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_tM3Uphqw_-c"
   },
   "source": [
    "What to do? Well we can just resize all the images in our input dataset, tensorflow provides a handy helper function for just this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "input_train_big_tensor = tf.image.resize_images(input_train_orig, [INPUT_DIM, INPUT_DIM])\n",
    "input_test_big_tensor  = tf.image.resize_images(input_test_orig, [INPUT_DIM, INPUT_DIM])\n",
    "\n",
    "with K.backend.get_session().as_default():\n",
    "    input_train_big = input_train_big_tensor.eval().astype('uint8')\n",
    "    input_test_big  = input_test_big_tensor.eval().astype('uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run the resized images through a preprocessing function provided by VGG19 - this just converts the channels to BGR instead of RGB, then subtracts the average BGR values for the `ImageNet` dataset from each pixel in our input images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "input_train_preprocessed = K.applications.vgg19.preprocess_input(input_train_big)\n",
    "input_test_preprocessed = K.applications.vgg19.preprocess_input(input_test_big)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise the Preprocessing\n",
    "\n",
    "Let's check that the resized images look somewhat similar to the original images:\n",
    "\n",
    "Take a note though, that the preprocessing function has made some of the RGB channels negative (and made the data type `float32`), here I've cast the data type to `uint8` to make visualisation effective, but it means that some channels overflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 5\n",
    "num = 6\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.subplot(311)\n",
    "plt.title('Original')\n",
    "plt.imshow(np.concatenate(input_train_orig[start:start+num], axis=1))\n",
    "\n",
    "plt.subplot(312)\n",
    "plt.title('Resized')\n",
    "plt.imshow(np.concatenate(input_train_big[start:start+num], axis=1))\n",
    "\n",
    "plt.subplot(313)\n",
    "plt.title('Preprocessed')\n",
    "plt.imshow(np.concatenate(input_train_preprocessed[start:start+num].astype('uint8'), axis=1))\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to check we understand what happened, we can look at the transformation of the top left pixel of each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original')\n",
    "print(' Type:', input_train_orig.dtype)\n",
    "print(' Values:', input_train_orig[0,0,0])\n",
    "print('\\nResized')\n",
    "print(' Type:', input_train_big.dtype)\n",
    "print(' Values:', input_train_big[0,0,0])\n",
    "print('\\nPreprocessed (Convert tp BGR and subtract Imagenet Means)')\n",
    "print(' Type:', input_train_preprocessed.dtype)\n",
    "print(' Values:', input_train_preprocessed[0,0,0])\n",
    "\n",
    "\n",
    "IMAGENET_BGR_MEANS = [103.939, 116.779, 123.68]\n",
    "print('\\nManually Processed (Flipped and ImageNet means subtracted)')\n",
    "print(' Values:', np.flip(input_train_big[0,0,0], axis=0) - IMAGENET_BGR_MEANS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3D9WgHZgw_-p"
   },
   "source": [
    "# Attach and Train our own Layers\n",
    "\n",
    "Now we create our own fresh layers, attach them to the VGG19 model we imported, and train the resulting franken-model, which we can then run our testing dataset on and see how it performs!\n",
    "\n",
    "We're first going to flatten the output of the VGG model so we have a single dimensional tensor of the last layer in the VGG model, then attach that to three fully connected layers with 512, 512, and 128 neurons respectively. Finally we will have a fully connected layer with 10 neurons (one for each class) as the output layer.\n",
    "\n",
    "When the network produces an output for a single input, it will have 10 values between 0 and 1, and the index of the highest output is the prediction of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mmd99mWvw_-q"
   },
   "outputs": [],
   "source": [
    "# Create a sequence of fully-connected layers that build on the imported vgg19 network\n",
    "# To do this we use the keras functional API\n",
    "x = K.layers.Flatten()(vgg19.output)\n",
    "x = K.layers.Dense(261, activation='relu')(x)\n",
    "output = K.layers.Dense(TRUTH_CLASSES, activation='softmax')(x)\n",
    "\n",
    "# Wrap the layer sequence in a Keras Model, required for running the training\n",
    "model = K.models.Model(vgg19.input, output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've put together the model we need to decide some of the parameters that will be used for training, and compile the model, which configures the tensorflow models for training.\n",
    "\n",
    "When we compile this model we give it:\n",
    "- `optimiser`: The optimiser controls the learning rate of the model, updates to the weights.\n",
    "- `loss`: The type of function used to generate an measure of how well the model is performing on the data, the closet the loss measurement gets to 0, the better the model performed on a given dataset\n",
    "- `metrics`: Functions used to judge the model performance, while this is similar to the loss function, they serve  different purposes and it's easier for a human to understand accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OilHBXYaw_-v"
   },
   "outputs": [],
   "source": [
    "optimizer = 'adam'\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Tensorboard for training visualisation\n",
    "\n",
    "This is an optional step, but pretty useful for seeing how things are going. Run the following in the directrory of the notebook to start tensorboard (it will have been installed when we installed tensorflow)\n",
    "\n",
    "```\n",
    "tensorboard --logdir graph\n",
    "```\n",
    "\n",
    "We then define a callback that will write training logs to the same directory we have as the `--logdir` argument to tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tb_callback(optimizer, batch):\n",
    "    train_name = \"{time} optimizer={op} batch={batch}\".format(\n",
    "        time=time.strftime(\"%Y-%m-%d %H%M\"),\n",
    "        batch=batch,\n",
    "        op=optimizer)\n",
    "    return K.callbacks.TensorBoard(log_dir='./graph/' + train_name, write_graph=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we get to actually train the network (Keras calls this 'fitting'). \n",
    "\n",
    "The key things here are:\n",
    "- `epochs`: One full presentation of all entries the training dataset to the network\n",
    "- `batch`: How many entries to present to the network before performing a gradient update (changing weights, which is how the network really learns)\n",
    "- `validation_split`: Portion of the training data set aside and not used for training, but instead used for validation (checking if we've overtrained the network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BeuoV6xzw_-0",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch=32\n",
    "tensorboard_callback = get_tb_callback(optimizer, batch)\n",
    "h = model.fit(\n",
    "    input_train_preprocessed,\n",
    "    truth_train,\n",
    "    epochs=2,\n",
    "    batch_size=batch,\n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Performance\n",
    "\n",
    "It's important to check the accuracy of the model on data that wasn't part of the training process, to validate that the model has not been overtrained on the training data. This is what we use the testing set of CIFAR 10 for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w8hlfyMww_-3"
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(input_test_preprocessed, truth_test)\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc * 100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matricies are an excellent way to provide visibility into any classes the model is performing poorly on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "test_pred = model.predict(input_test_preprocessed, verbose=1, batch_size=256)\n",
    "test_pred_final = np.argmax(test_pred, axis=1)\n",
    "test_confusion = sklearn.metrics.confusion_matrix(truth_test_orig, test_pred_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(test_confusion, ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'], normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tNZqP-D4w_-9"
   },
   "source": [
    "# Make Some Predictions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating predictions on the testing dataset and storing them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(input_test_preprocessed, verbose=1, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a sample of those predictions using the function we created for that purpose earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JkRgENdJw_-9"
   },
   "outputs": [],
   "source": [
    "plot_images(input_test_orig, truth_test, range(15), preds=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps - tweak the training\n",
    "\n",
    "Now it becomes a game of experiments, we can do lots of things to improve the model performance, e.g:\n",
    "- Reducing the learning rate, and training for more epochs, to reduce the risk of overtraining\n",
    "- Implement layers that are designed to mitigate overtraining so we can train for longer (e.g. Dropout layers)\n",
    "- Perform data augmentation to generate more, slightly different data (things like flippign and sliding images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train More Models!\n",
    "\n",
    "We can train another model with different parameters and see how the training progress differs in tensorboard, say we want to experiment with how batch size affects training..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = [30, 30, 30, 32, 32, 32, 34, 34, 34]\n",
    "optimizers = ['sgd']\n",
    "\n",
    "\n",
    "for op in optimizers:\n",
    "    for bat in batches:\n",
    "        print('Optimizer:', op, 'Batch:', bat)\n",
    "        # create another model\n",
    "        x = K.layers.Flatten()(vgg19.output)\n",
    "        x = K.layers.Dense(261, activation='relu')(x)\n",
    "        output = K.layers.Dense(TRUTH_CLASSES, activation='softmax')(x)\n",
    "        newmodel  = K.models.Model(vgg19.input, output)\n",
    "        \n",
    "        newmodel.compile(optimizer=op, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        newmodel.fit(\n",
    "            input_train_preprocessed,\n",
    "            truth_train,\n",
    "            epochs=10,\n",
    "            batch_size=bat,\n",
    "            shuffle=True,\n",
    "            verbose=2,\n",
    "            validation_split=0.2,\n",
    "            callbacks=[get_tb_callback(op, bat)]\n",
    "        )\n",
    "        \n",
    "        test_loss, test_acc = newmodel.evaluate(input_test_preprocessed, truth_test)\n",
    "        print('Test loss:', test_loss)\n",
    "        print('Test accuracy:', test_acc * 100, '%')\n",
    "        print('----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:EngProj2018]",
   "language": "python",
   "name": "conda-env-EngProj2018-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
