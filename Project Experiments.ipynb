{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = 9.5, 6\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras as K\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sklearn as skl\n",
    "import sklearn.model_selection as skl_model_selection\n",
    "import itertools\n",
    "import time\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "TRUTH_CLASSES = 10\n",
    "INPUT_DIM = 48\n",
    "\n",
    "(input_train_orig, truth_train_orig), (input_test_orig, truth_test_orig) = K.datasets.cifar10.load_data()\n",
    "\n",
    "input_train_big_tensor = tf.image.resize_images(input_train_orig, [INPUT_DIM, INPUT_DIM])\n",
    "input_test_big_tensor  = tf.image.resize_images(input_test_orig, [INPUT_DIM, INPUT_DIM])\n",
    "\n",
    "with K.backend.get_session().as_default():\n",
    "    input_train_big = input_train_big_tensor.eval().astype('uint8')\n",
    "    input_test_big  = input_test_big_tensor.eval().astype('uint8')\n",
    "    \n",
    "input_train_preprocessed = K.applications.vgg19.preprocess_input(input_train_big)\n",
    "input_test_preprocessed = K.applications.vgg19.preprocess_input(input_test_big)\n",
    "truth_train = K.utils.to_categorical(truth_train_orig, TRUTH_CLASSES)\n",
    "truth_test = K.utils.to_categorical(truth_test_orig, TRUTH_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name(num):\n",
    "    return \"model-{num}\".format(num=num)\n",
    "\n",
    "def get_tb_callback(name):\n",
    "    path = \"./exp-graphs/\" + name\n",
    "    return K.callbacks.TensorBoard(log_dir=path, write_graph=False)\n",
    "\n",
    "def get_checkpointing_callback(name):\n",
    "    path = \"./exp-models/\" + name + \"-epoch-{epoch:02d}.hdf5\"\n",
    "    return K.callbacks.ModelCheckpoint(filepath=path, verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encapsulation of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OVERTRAINING_FACTOR = 2.5\n",
    "def create_model(model_no, initial_epochs=6, batch=32):\n",
    "    K.backend.clear_session()\n",
    "    np.random.seed(model_no)\n",
    "    \n",
    "    name = get_model_name(model_no)\n",
    "    best_weights = Path(\"./exp-models\") / (name + \"-overtrained.hdf5\")\n",
    "    overtrained_weights = Path(\"./exp-models\") / (name + \"-overtrained.hdf5\")\n",
    "    graphs_dir = Path(\"./exp-graph\") / name\n",
    "    \n",
    "    if not overtrained_weights.exists():\n",
    "        print(\">>> Begin train for model\", model_no)\n",
    "        bag_indexes = np.random.randint(0, len(input_train_preprocessed)-1, len(input_train_preprocessed))\n",
    "        x_train_bag = input_train_preprocessed[bag_indexes]\n",
    "        y_train_bag = truth_train[bag_indexes]\n",
    "    \n",
    "    \n",
    "        if best_weights.exists():\n",
    "            best_weights.unlink()\n",
    "        if graphs_dir.exists():\n",
    "            shutil.rmtree(graphs_dir)\n",
    "\n",
    "        tensorboard_callback = get_tb_callback(name)\n",
    "        checkpoint_callback = get_checkpointing_callback(name)\n",
    "\n",
    "        vgg19 = K.applications.vgg19.VGG19(\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            input_shape=(INPUT_DIM, INPUT_DIM, 3),\n",
    "        )\n",
    "        \n",
    "        for layer in vgg19.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "        x = K.layers.Flatten()(vgg19.output)\n",
    "        x = K.layers.Dense(261, activation='relu')(x)\n",
    "        output = K.layers.Dense(TRUTH_CLASSES, activation='softmax')(x)\n",
    "        model = K.models.Model(vgg19.input, output)\n",
    "\n",
    "        model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        h = model.fit(\n",
    "            x_train_bag,\n",
    "            y_train_bag,\n",
    "            epochs=initial_epochs,\n",
    "            batch_size=batch,\n",
    "            shuffle=True,\n",
    "            verbose=2,\n",
    "            validation_split=0.2,\n",
    "            callbacks=[tensorboard_callback, checkpoint_callback]\n",
    "        )\n",
    "        best_epoch = np.argmin(h.history[\"val_loss\"]) + 1\n",
    "        overtrained_epoch = int(best_epoch * OVERTRAINING_FACTOR)\n",
    "        print(\">>> Best epoch found:\", best_epoch, \"Overtraining to:\", overtrained_epoch)\n",
    "        \n",
    "        h = model.fit(\n",
    "            x_train_bag,\n",
    "            y_train_bag,\n",
    "            initial_epoch=initial_epochs,\n",
    "            epochs=overtrained_epoch,\n",
    "            batch_size=batch,\n",
    "            shuffle=True,\n",
    "            verbose=1,\n",
    "            validation_split=0.2,\n",
    "            callbacks=[tensorboard_callback]\n",
    "        )\n",
    "        model.save(overtrained_weights)\n",
    "\n",
    "    print(\">>> Obtained best and overtrained for model\", model_no)\n",
    "    return best_weights, overtrained_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train all the networks, and obtain predictions on the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "NUM_MODELS = 100\n",
    "Path(\"./exp-models\").mkdir(exist_ok=True)\n",
    "accuracy_best = []\n",
    "accuracy_over = []\n",
    "predictions_best = []\n",
    "predictions_over = []\n",
    "for model_no in range(1, NUM_MODELS+1):\n",
    "    \n",
    "    # if predictions and accuracy file does not exist - run evaluations and predictions and save results\n",
    "    best_weights_path, overtrained_weights_path = create_model(model_no)\n",
    "    \n",
    "    bm = K.models.load_model(best_weights_path)\n",
    "    om = K.models.load_model(overtrained_weights_path)\n",
    "    \n",
    "    predictions_best.append(bm.evaluate(input_test_preprocessed, truth_test, verbose=1))\n",
    "    predictions_over.append(om.evaluate(input_test_preprocessed, truth_test, verbose=1))\n",
    "    \n",
    "    predictions_best.append(bm.predict(input_test_preprocessed, verbose=1))\n",
    "    predictions_over.append(om.predict(input_test_preprocessed, verbose=1))\n",
    "    \n",
    "ensemble_pred_best = np.mean(np.array(predictions_best), axis=0)\n",
    "ensemble_pred_over = np.mean(np.array(predictions_best), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Loss and Accuracy for the Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_best = K.losses.categorical_crossentropy(ensemble_pred_best, truth_test)\n",
    "metrics_over = K.losses.categorical_crossentropy(ensemble_pred_over, truth_test)\n",
    "print(\"Best:\", metrics_best)\n",
    "print(\"Over:\", metrics_over)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create confusion matrices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
